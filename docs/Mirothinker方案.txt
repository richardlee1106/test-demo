下面是一个**可以落地实施的“地理感知 RAG”技术方案**，目标就是让 LLM 像理解文本语义一样，理解“南门、对面、500m 内”等空间语义，同时尽量少花 token。

---

## 一、核心思路：文本语义交给向量检索，几何关系交给空间索引

不要指望把经纬度本身当成 embedding 让 LLM“学会空间”，而是要：

1. **文本相关**（“咖啡馆”“评分高”“环境安静”等）  
   → 用普通文本 embedding + 向量数据库处理。

2. **空间相关**（“南门”“对面”“500m 内”等）  
   → 用 **地理编码 + 空间索引（GeoHash / H3 / PostGIS / Milvus Geometry）** 做精确过滤和距离计算。

3. **LLM 只负责：**
   - 从用户自然语言中解析出：地名、方位词、距离条件、类别、评分条件等；
   - 组装成 **结构化查询（SQL / 向量数据库过滤条件）**；
   - 对检索结果做自然语言回答和轻量推理。

这样既保证空间准确性，又节省大量 token（只把少量结果喂给 LLM）。

---

## 二、数据侧设计：如何存 geojson + 向量 + 空间索引

以“POI（兴趣点）/ 店铺”数据为例，假设数据源是 GeoJSON：

```json
{
  "type": "Feature",
  "properties": {
    "id": 1,
    "name": "星巴克咖啡",
    "address": "武汉理工大学南门对面",
    "rating": 4.7,
    "category": "咖啡馆",
    "description": "环境优雅，咖啡品质上乘，学习氛围好"
  },
  "geometry": {
    "type": "Point",
    "coordinates": [114.4176, 30.4674]
  }
}
```

### 1. 结构化表设计（推荐 Postgres + PostGIS + pgvector）

```sql
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE pois (
    id          SERIAL PRIMARY KEY,
    name        TEXT,
    address     TEXT,
    category    TEXT,
    rating      FLOAT,
    -- 空间字段
    geom        GEOMETRY(POINT, 4326),   -- 原始经纬度
    geohash     TEXT,                    -- 快速空间索引（方格）
    h3_index    TEXT,                    -- 可选，六边形网格
    -- 语义 embedding
    embedding   VECTOR(384),
    created_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_pois_geom    ON pois USING GIST (geom);
CREATE INDEX idx_pois_geohash ON pois USING BTREE (geohash);
CREATE INDEX idx_pois_h3      ON pois USING BTREE (h3_index);
CREATE INDEX idx_pois_emb     ON pois USING HNSW (embedding vector_cosine_ops);
```

> 如果不方便用 Postgres，也可以用：  
> - Elasticsearch：`geo_point / geo_shape` + dense_vector + hybrid search  
> - Milvus：新版本的 `GEOMETRY` 字段 + RTREE 索引 + 向量字段  
> - Qdrant：向量字段 + `geo` filter（圆/矩形/多边形）[1][2]

### 2. 预处理流程（离线 ETL）

对每条 GeoJSON Feature：

1. **解析几何：**  
   `geom = ST_SetSRID(ST_MakePoint(lon, lat), 4326)`

2. **空间编码：**
   - **GeoHash**（简单易用）  
     - 使用 Python `geohash2` 或数据库函数，设定精度，例如：
       - 精度 9：单元格 ~386m
       - 精度 10：单元格 ~96m  
     - 存入 `geohash` 列；
   - 可选：**H3**（六边形，更适合大规模分析）按业务需要选择分辨率。

3. **文本 embedding：**
   - 拼接主要文本字段：  
     `text = f"{name} {category} {address} {description}"`  
   - 用多语种模型（如 `paraphrase-multilingual-MiniLM-L12-v2`）生成 384 维向量，存入 `embedding` 列。

4. **其他属性（评分、标签等）直接存列**，用于过滤/排序，RAG 用不到 LLM 就能直接取。

这样，每条 POI 就同时拥有：

- 精确空间信息：`geom`
- 快速空间网格索引：`geohash / h3_index`
- 语义 embedding：`embedding`
- 结构化属性：`rating, category ...`

---

## 三、查询侧：如何理解“南门”“对面”“500m 内”

以示例问题为例：

> 「武理工南门对面500m内有哪些评分高于4.5分的咖啡馆？」

### 1. LLM 做的事：**把自然语言解析成结构化约束**

通过 prompt 让 LLM 输出 JSON，例如：

```json
{
  "place_name": "武汉理工大学",
  "gate": "南门",
  "relative_position": "对面",
  "radius_m": 500,
  "min_rating": 4.5,
  "category": "咖啡馆"
}
```

解析要点：

- **实体识别：** “武理工” → “武汉理工大学”（可以靠 LLM + 你的地名库做匹配）。
- **方位词：** “南门”“对面”  
  - “南门” 表示：在学校南侧的一扇门 → 有标准门坐标，或者根据主校区中心 + 向南偏移预估；
  - “对面” 表示：以南门为中心，在门外一条路对面区域，通常可以近似为在南门外某个偏移距离的圆形区域。
- **距离：** “500m 内” → `radius_m = 500`
- **过滤：** “评分高于 4.5 分的咖啡馆” → `rating > 4.5 && category ~ '咖啡'`

> 这一步完全不需要空间计算，只是语义抽取，LLM 很擅长，而且 JSON token 很少。

### 2. 将 place/gate 变成坐标：地理编码 + 自有门点数据

1. 用地理编码服务（高德/百度，或自建 POI 表）：
   - `geocode("武汉理工大学")` → 校区中心点 `(lat_c, lon_c)`
2. “南门”：
   - 最好有一张 `campus_gates` 表，里面有每个校门的精确点位：
     ```sql
     SELECT lat, lon FROM campus_gates
       WHERE campus_name='武汉理工大学' AND gate_name='南门';
     ```
   - 如果没有，可以按固定规则：在校区中心点向南偏移 50–100m 作为南门近似。

得到南门坐标 `(lat_gate, lon_gate)`。

### 3. “对面”和“500m 内”转成空间约束

常见简单做法：

- **“对面”**：可以近似不做特殊处理，认为“以南门为圆心，门外 500m 内”都满足语义；  
  更精细可以：
  - 根据门外道路方向，构造一个相对于大门外侧的一扇圆扇形/矩形区域；
  - 这一步可以在 GIS 系统中预计算，不必让 LLM 算，以后 reuse。

- **“500m 内”**：直接用圆范围查询（PostGIS / Milvus / Qdrant 都支持）。

PostGIS 示例：

```sql
-- 查询南门 500m 圆范围内，评分>4.5 的咖啡馆
WITH gate AS (
  SELECT ST_SetSRID(ST_MakePoint(:lon_gate, :lat_gate), 4326) AS g
)
SELECT id, name, rating, ST_Distance(p.geom::geography, g::geography) AS dist_m
FROM pois p, gate
WHERE p.category = '咖啡馆'
  AND p.rating >= 4.5
  AND ST_DWithin(p.geom::geography, g::geography, 500)
ORDER BY dist_m
LIMIT 20;
```

> 这一层**不需要 embedding**，也不需要 LLM，把“500m 内”翻译成 ST_DWithin 就可以了。

### 4. 如何结合向量检索（当有语义偏好时）

若用户问的是：

> 「武理工南门对面500m内，**环境安静、适合自习、评分高** 的咖啡馆？」

那么除了 `radius` / `rating` 约束，还要考虑“环境安静”“适合自习”的语义：

流程改成 **空间过滤 + 语义排序**：

1. 先用空间条件把候选集缩到几百条以内：

```sql
WITH gate AS (... 同上 ...)
SELECT id, name, rating, embedding, geom
FROM pois p, gate
WHERE ST_DWithin(p.geom::geography, g::geography, 500)
  AND p.category = '咖啡馆'
  AND p.rating >= 4.0;   -- 稍微放宽
```

2. 对这些候选，在向量库里做相似度搜索：
   - Query embedding = `embed("环境安静 适合自习 的咖啡馆")`
   - Filter = `id IN (候选ID列表)`  
   → 返回前 k 条（比如 10）。

3. 把这 10 条的 `name/address/rating/具体距离` 组成简短 JSON 或表格喂进 LLM，让它生成最终回答。

这样：

- **空间约束保证“就在那附近”**；
- **向量相似度保证满足“环境安静、适合自习”**；
- **LLM 只看到 10 条记录，token 非常少**。

---

## 四、如何节省 token 又保证完整性和准确性

### 1. 在检索层就做好 80% 工作

- 由 **数据库/向量库完成：**
  - 空间过滤（圆 / GeoHash / H3 区块）；
  - 数值过滤（评分、价格、营业时间等）；
  - 语义排序（embedding 相似度）。

LLM 看到的是**已经高度筛选过的少量结果**，而不是所有原始数据。

### 2. 控制传给 LLM 的字段和格式

只传必要字段，例如：

```json
[
  {
    "name": "星巴克咖啡",
    "distance_m": 120,
    "rating": 4.7,
    "address": "武汉理工大学南门对面",
    "tags": ["安静", "适合自习"]
  },
  {
    "name": "瑞幸咖啡",
    "distance_m": 230,
    "rating": 4.6,
    "address": "武汉理工大学南门对面100米",
    "tags": ["便宜", "外卖多"]
  }
]
```

然后 prompt 只要求：

> “根据以上 JSON，回答用户问题，不要虚构不存在的店铺。”

LLM 只做最后的自然语言组织和轻微排序解释，token 开销非常小。

### 3. 让 LLM 输出**结构化查询而不是直接算空间**

Prompt 模式可以设计成：

> “你是地理查询编译器，把用户问题翻译成一个 JSON，里面包含：place_name, gate, radius, min_rating, category, semantic_query。不要回答结论。”

再由后端服务根据这个 JSON 去数据库 / 向量库执行查询。

---

## 五、GraphRAG 的扩展：把空间关系建成图

如果你希望更复杂的“路线、连通性、邻近关系”推理，可以在此基础上加一层 GraphRAG：

- 节点：POI、地标（学校、地铁站）、道路节点、校门。
- 边：  
  - “距离 < 200m” → 邻接边；
  - “同一条街对面” → 对面边；
  - “步行可达（10 分钟内）” → 可达边。

Graph 数据库（如 Neo4j / ArangoDB / TigerGraph）可以：

- 很快回答：“从南门出发，步行 10 分钟内可达的咖啡馆有哪些？”  
- LLM 负责翻译自然语言 → 图查询（Cypher/AQL） → 执行 → 再由 LLM 用自然语言解释路径和理由。

这样空间“感知”就不仅仅是点+距离，而是包含“连通性”和“地理网络结构”，比单纯 RAG 更“聪明”。

---

## 六、总结：一套可落地的技术路线

1. **数据层**
   - 把 GeoJSON 转成关系表 + PostGIS 几何字段；
   - 生成 GeoHash/H3 索引列，用于快速“附近”过滤；
   - 用文本 embedding 模型（多语种）生成向量 embedding，存入 pgvector / Milvus / Qdrant 等。

2. **检索层（核心）**
   - 由 LLM 把自然语言解析成结构化约束（地点、门、距离、方向、评分、类别、语义偏好）；
   - 用 geocode + 门点表把“武理工南门”变成具体坐标；
   - 用空间查询（ST_DWithin / geo filter）做 **“500m 内”** 筛选；
   - 用结构化过滤（评分>4.5、类别=咖啡馆）缩小集合；
   - 如果有语义偏好，再用 embedding 做二次排序。

3. **生成层**
   - 只把前 N 条候选（含 name/address/rating/distance 等紧凑字段）传给 LLM；
   - LLM 负责自然语言总结 + 解释（为什么推荐、距离多远等）。

4. **GraphRAG（可选）**
   - 把 POI/道路/地铁/校门建成空间图；
   - 复杂路线和“可达性”问题交给图数据库 + LLM 组合处理。

这样，你就能让 LLM 在 RAG/GraphRAG 体系里真正**“具备位置感”**，而不用把经纬度硬塞进 embedding 里，也不会浪费 token，同时保证空间计算的严谨和结果的可解释性。  

如果你愿意，我可以按你目前的技术栈（例如：Elasticsearch / Milvus / Postgres / Qdrant）再给一份对应的具体建表、索引和查询示例。  

---

References  
[1] Geospatial Vector Search with Qdrant. <https://geo.rocks/post/geospatial-vector-search-qdrant/>  
[2] Bringing Geospatial Filtering and Vector Search Together with Geometry Fields and RTREE in Milvus. <https://milvus.io/blog/unlock-geo-vector-search-with-geometry-fields-and-rtree-index-in-milvus.md>  
[3] Crafting a hybrid geospatial RAG application with Elastic & Amazon Bedrock. <https://www.elastic.co/blog/hybrid-geospatial-rag-application-elastic-amazon-bedrock>  
[4] Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions. <https://arxiv.org/abs/2502.18470>